{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqk+cOT3jQnR5PT6fQVuwP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YahiaML/Linkedin-Web-scraping-series/blob/main/5_Scrap_all_main_pages.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qE9G2od9BNkF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Lists to store data\n",
        "job_titles, job_links, company_names, locations, posted_from_list, job_types, experience_list, other_info_list = [],[],[],[],[],[],[],[]\n",
        "\n",
        "# Step 1: Determine URL pattern\n",
        "for page_number in range(1,32):\n",
        "    url = f'https://www.bayt.com/en/egypt/jobs/data-analysis-jobs/?page={page_number}'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Step 2: Use find_all to get the containers that hold all job info\n",
        "    job_containers = soup.find_all('li', {'class': 'has-pointer-d'})\n",
        "\n",
        "    # Step 3: Iterate over each container and extract relevant data\n",
        "    for container in job_containers:\n",
        "\n",
        "        # Job title\n",
        "        try:\n",
        "            job_title = container.find('h2').text.strip()\n",
        "        except:\n",
        "            job_title = np.nan\n",
        "\n",
        "        # Job link\n",
        "        try:\n",
        "            job_link = container.find('h2').find('a').get('href')\n",
        "            job_link = \"https://www.bayt.com\" + job_link  # Making it a full URL\n",
        "        except:\n",
        "            job_link = np.nan\n",
        "\n",
        "        # Company name\n",
        "        try:\n",
        "            company_name = container.find('b').text.strip()\n",
        "        except:\n",
        "            company_name = np.nan\n",
        "\n",
        "        # Location\n",
        "        try:\n",
        "            location = container.find('div', {'class': 't-mute'}).text.strip()\n",
        "        except:\n",
        "            location = np.nan\n",
        "\n",
        "        # Posted from\n",
        "        try:\n",
        "            posted_from = container.find('div', {'data-automation-id': 'job-active-date'}).text.strip()\n",
        "        except:\n",
        "            posted_from = np.nan\n",
        "\n",
        "        # Job type (Remote/On-site)\n",
        "        try:\n",
        "            job_type = container.find('li', {'class': 'jb-label-remote'}).text.strip()\n",
        "        except:\n",
        "            job_type = np.nan\n",
        "\n",
        "        # Experience level and years of experience\n",
        "        try:\n",
        "            experience = container.find('li', {'class': 'jb-label-careerlevel'}).text.strip()\n",
        "        except:\n",
        "            experience = np.nan\n",
        "\n",
        "        # Additional info (if any)\n",
        "        try:\n",
        "            other_info = container.find('div', {'class': 'm10t t-small'}).text.strip()\n",
        "        except:\n",
        "            other_info = np.nan\n",
        "\n",
        "        # Append info to relevant lists\n",
        "        job_titles.append(job_title)\n",
        "        job_links.append(job_link)\n",
        "        company_names.append(company_name)\n",
        "        locations.append(location)\n",
        "        posted_from_list.append(posted_from)\n",
        "        job_types.append(job_type)\n",
        "        experience_list.append(experience)\n",
        "        other_info_list.append(other_info)\n",
        "\n",
        "# Create a DataFrame\n",
        "jobs_df = pd.DataFrame({'Job Title': job_titles,'Job Link': job_links,'Company Name': company_names,'Location': locations,'Posted From': posted_from_list,'Job Type': job_types,'Experience': experience_list,\"Additional Info\": other_info_list})\n",
        "\n",
        "jobs_df\n"
      ]
    }
  ]
}