{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtGqKeQxkkSSur40s4HLEJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YahiaML/Linkedin-Web-scraping-series/blob/main/2_Find_%26_Find_all.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "osUIpVzG32EG"
      },
      "outputs": [],
      "source": [
        "# First, install the required libraries if you're running this for the first time\n",
        "# !pip install requests beautifulsoup4\n",
        "\n",
        "# Import necessary modules\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "# Define the URL of the page you want to scrape\n",
        "url = 'https://wuzzuf.net/a/Student-Jobs-in-Egypt?filters%5Bcareer_level%5D%5B0%5D=Student'\n",
        "\n",
        "# Send a GET request to fetch the HTML content of the webpage\n",
        "response = requests.get(url)\n",
        "\n",
        "# Create a BeautifulSoup object and specify the parser\n",
        "soup = BeautifulSoup(response.text, 'html.parser')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- FINDING A SINGLE ELEMENT WITH `find()` ---\n",
        "\n",
        "# Using find() to locate the first job title on the page\n",
        "# In this case, it finds the first <h2> tag\n",
        "first_job_title = soup.find('h2')\n",
        "\n",
        "# Print the text inside the first job title\n",
        "# The .text attribute is used to extract the text content between the <h2> tags\n",
        "print(f\"First job title: {first_job_title.text}\")"
      ],
      "metadata": {
        "id": "1K10THcP38pY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- FINDING AN ELEMENT WITH A SPECIFIC ATTRIBUTE ---\n",
        "\n",
        "# Now, let's search for an element using its class attribute\n",
        "# We'll look for a <div> with the class \"css-1lh32fc\" which holds the job type information\n",
        "job_type = soup.find('div', {'class': 'css-1lh32fc'})\n",
        "\n",
        "# Print the job type div, if found\n",
        "print(f\"Job type: {job_type.text if job_type else 'Job type not found'}\")\n"
      ],
      "metadata": {
        "id": "R7FiHnhX97hQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- FINDING MULTIPLE ELEMENTS WITH `find_all()` ---\n",
        "\n",
        "# Now, use find_all() to retrieve all job titles on the page (all <h2> tags)\n",
        "all_job_titles = soup.find_all('h2')\n",
        "\n",
        "# Loop through each job title and print the text\n",
        "print(\"\\nAll job titles on the page:\")\n",
        "for title in all_job_titles:\n",
        "    print(title.text)\n",
        "\n",
        "# --- EXPLANATION OF THE DIFFERENCE BETWEEN find() AND find_all() ---\n",
        "\n",
        "# `find()` stops after finding the first matching tag\n",
        "# `find_all()` returns a list of all matching tags, which allows you to gather and process multiple elements"
      ],
      "metadata": {
        "id": "9bLl-8HY9-Bv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}